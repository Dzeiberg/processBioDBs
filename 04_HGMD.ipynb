{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Bio import Entrez\n",
    "\n",
    "# Entrez.email = \"zeiberg.d@northeastern.edu\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from easydict import EasyDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSequenceFromNPID(npid):\n",
    "    \"Return the protein sequence from \"\n",
    "    handle = Entrez.efetch(db=\"protein\",id=npid, rettype=\"fasta\", retmode=\"text\")\n",
    "    lines = handle.readlines()\n",
    "    lines = [l.strip() for l in lines]\n",
    "    return \"\".join(lines[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"/ssdata/hgmd/HGMD_PRO_2019_1_hg19.vcf\",delimiter=\"\\t\",header=14)\n",
    "df = pd.read_csv(\"/data/projects/processBio/hgmd/HGMD_PRO_2019_1_hg19.vcf\",delimiter=\"\\t\",header=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfo(row):\n",
    "    d = EasyDict()\n",
    "    for vals in row[\"INFO\"].split(\";\"):\n",
    "        k,v = vals.split(\"=\")\n",
    "        d[k] = v\n",
    "    if \"PROT\" in d:\n",
    "        d.pid, d.variant = d.PROT.split(\":\")\n",
    "    elif \"DB\" in d:\n",
    "        d.pid = \"\"\n",
    "        d.variant=\"\"\n",
    "        rsid= d.DB.replace(\"rs\",\"\")\n",
    "        \n",
    "    else:\n",
    "        return d\n",
    "    try:\n",
    "        _,d.variant = d.variant.split(\".\")\n",
    "        d.reference,location,d.missense = d.variant[0],int(d.variant[1:-1]),d.variant[-1]\n",
    "    except ValueError:\n",
    "        return d\n",
    "    d.loc = location - 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allGenes = set()\n",
    "genesWithAtleastOneVariant = set()\n",
    "validInfo = []\n",
    "for i,row in tqdm(df.iterrows()):\n",
    "    info = getInfo(row)\n",
    "    allGenes.add(info.GENE)\n",
    "    if \"missense\" in info:\n",
    "        genesWithAtleastOneVariant.add(info.GENE)\n",
    "        validInfo.append(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All missense variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variantDF = pd.DataFrame(validInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variantDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of genes with at least one variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variantDF.GENE.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = EasyDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for npid in tqdm(protein_ids):\n",
    "    sequences[npid] = getSequenceFromNPID(npid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(sequences, open(\"/ssdata/hgmd/sequences.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from easydict import EasyDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences = pickle.load(open(\"/ssdata/hgmd/sequences.pkl\",\"rb\"))\n",
    "sequences = pickle.load(open(\"/data/projects/processBio/hgmd/sequences.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = []\n",
    "errors = {\"match\":[]}\n",
    "for idx,row in tqdm(variantDF.iterrows(),total=variantDF.shape[0]):\n",
    "    s = sequences[row.pid]\n",
    "    loc = row[\"loc\"]\n",
    "    variant = s[:loc] + row.missense + s[loc+1:]\n",
    "    if loc < len(s) and s[loc] == row.reference:\n",
    "        seqs.append(variant)\n",
    "    else:\n",
    "        errors[\"match\"].append(idx)\n",
    "        seqs.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variantDF = variantDF.assign(seq=seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variantDF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pedja says DM only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variantDF = variantDF[(variantDF.CLASS == \"DM\") & (~variantDF.PROT.str.contains(\"\\*\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variantDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variantDF.to_csv(\"/data/projects/processBio/hgmd/variant_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variantDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "import os\n",
    "import torch.nn as nn\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1,2,3'\n",
    "\n",
    "\n",
    "model, alphabet = esm.pretrained.esm1b_t33_650M_UR50S()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "# model = nn.DataParallel(model.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 500\n",
    "\n",
    "Data = list(variantDF.apply(lambda row: row.seq[max(0,\n",
    "                                                   row[\"loc\"] - WINDOW_SIZE) : min(len(row.seq),\n",
    "                                                                                              row[\"loc\"] + WINDOW_SIZE + 1)],axis=1).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE=1\n",
    "representations = []\n",
    "for start in trange(0,len(Data),BATCHSIZE):\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(Data[start : start + BATCHSIZE])\n",
    "    # Extract per-residue representations (on CPU)\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens.to(\"cuda:1\"), repr_layers=[33], return_contacts=True)\n",
    "    token_representations = results[\"representations\"][33].cpu()\n",
    "    del results, batch_labels, batch_strs, batch_tokens\n",
    "    representations.append(token_representations[0,1:-1].cpu().numpy())\n",
    "    del token_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variantDF = variantDF.assign(representation=representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variantDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processBioDBs.utilities import prepSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variantDF = variantDF.assign(xi=variantDF.apply(lambda row: prepSeq(row.representation,\n",
    "                                                                 row[\"loc\"],\n",
    "                                                                 originalWindowSize=WINDOW_SIZE),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack(variantDF.xi.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/data/projects/processBio/hgmd/X.npy\",X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, variantDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
